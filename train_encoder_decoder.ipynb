{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import migrate\n",
    "from config import patience, batch_size, epochs, num_train_samples, num_valid_samples\n",
    "from data_generator import train_gen, valid_gen\n",
    "from model import build_encoder_decoder\n",
    "from utils import overall_loss, get_available_cpus, get_available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_board = keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model_names = checkpoint_models_path + 'model.{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience / 4), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCbk(keras.callbacks.Callback):\n",
    "    def __init__(self, model):\n",
    "        keras.callbacks.Callback.__init__(self)\n",
    "        self.model_to_save = model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        fmt = checkpoint_models_path + 'model.%02d-%.4f.hdf5'\n",
    "        self.model_to_save.save(fmt % (epoch, logs['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = len(get_available_gpus())\n",
    "if num_gpu >= 2:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        if pretrained_path is not None:\n",
    "            model = build_encoder_decoder()\n",
    "            model.load_weights(pretrained_path)\n",
    "        else:\n",
    "            model = build_encoder_decoder()\n",
    "            migrate.migrate_model(model)\n",
    "\n",
    "    new_model = multi_gpu_model(model, gpus=num_gpu)\n",
    "    # rewrite the callback: saving through the original model and not the multi-gpu model.\n",
    "    model_checkpoint = MyCbk(model)\n",
    "else:\n",
    "    if pretrained_path is not None:\n",
    "        new_model = build_encoder_decoder()\n",
    "        new_model.load_weights(pretrained_path)\n",
    "    else:\n",
    "        new_model = build_encoder_decoder()\n",
    "        migrate.migrate_model(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='nadam', loss=overall_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpu = get_available_cpus()\n",
    "workers = int(round(num_cpu / 2))\n",
    "print('num_gpu={}\\nnum_cpu={}\\nworkers={}\\ntrained_models_path={}.'.format(num_gpu, num_cpu, workers, checkpoint_models_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tensor_board, model_checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(train_gen(), steps_per_epoch=num_train_samples // batch_size, validation_data=valid_gen(), validation_steps=num_valid_samples // batch_size, epochs=epochs, verbose=1, callbacks=callbacks, use_multiprocessing=True, workers=workers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
